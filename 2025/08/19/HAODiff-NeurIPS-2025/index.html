<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>HAODiff(NeurIPS 2025) | -UNSWEAR-</title><meta name="author" content="unswear"><meta name="copyright" content="unswear"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="HAODiff: Human-Aware One-Step Diffusion  via Dual-Prompt Guidance   Jue Gong, Tingyu Yang, Jingkai Wang, Zheng Chen, Xing Liu, Hong Gu, Yulun Zhang, Xiaokang Yang   â€œA novel one-step diffusion model">
<meta property="og:type" content="article">
<meta property="og:title" content="HAODiff(NeurIPS 2025)">
<meta property="og:url" content="http://example.com/2025/08/19/HAODiff-NeurIPS-2025/index.html">
<meta property="og:site_name" content="-UNSWEAR-">
<meta property="og:description" content="HAODiff: Human-Aware One-Step Diffusion  via Dual-Prompt Guidance   Jue Gong, Tingyu Yang, Jingkai Wang, Zheng Chen, Xing Liu, Hong Gu, Yulun Zhang, Xiaokang Yang   â€œA novel one-step diffusion model">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://imgapi.jinghuashang.cn/random?t=17627393339646338">
<meta property="article:published_time" content="2025-08-19T14:56:42.000Z">
<meta property="article:modified_time" content="2025-11-10T01:48:53.965Z">
<meta property="article:author" content="unswear">
<meta property="article:tag" content="ä¸ªäººç§‘ç ”é¡¹ç›®">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://imgapi.jinghuashang.cn/random?t=17627393339646338"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "HAODiff(NeurIPS 2025)",
  "url": "http://example.com/2025/08/19/HAODiff-NeurIPS-2025/",
  "image": "https://imgapi.jinghuashang.cn/random?t=17627393339646338",
  "datePublished": "2025-08-19T14:56:42.000Z",
  "dateModified": "2025-11-10T01:48:53.965Z",
  "author": [
    {
      "@type": "Person",
      "name": "unswear",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/08/19/HAODiff-NeurIPS-2025/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"æœªæ‰¾åˆ°ç¬¦åˆæ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}","hits_stats":"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶å¤±è´¥',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'åŠ è½½æ›´å¤š'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'HAODiff(NeurIPS 2025)',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background: 0000;"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://s21.ax1x.com/2025/06/24/pVeefKS.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">1</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-th-list"></i><span> Categories</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://imgapi.jinghuashang.cn/random?t=17627393339646338);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">-UNSWEAR-</span></a><a class="nav-page-title" href="/"><span class="site-name">HAODiff(NeurIPS 2025)</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-th-list"></i><span> Categories</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">HAODiff(NeurIPS 2025)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2025-08-19T14:56:42.000Z" title="å‘è¡¨äº 2025-08-19 22:56:42">2025-08-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2025-11-10T01:48:53.965Z" title="æ›´æ–°äº 2025-11-10 09:48:53">2025-11-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">ç§‘ç ”</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">æµè§ˆé‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 align="center">
HAODiff: Human-Aware One-Step Diffusion <br> via Dual-Prompt Guidance
</h1>
<p align="center">
<a target="_blank" rel="noopener" href="https://github.com/gobunu">Jue Gong</a>,
<a target="_blank" rel="noopener" href="https://github.com/frakenation">Tingyu Yang</a>,
<a target="_blank" rel="noopener" href="https://github.com/jkwang28">Jingkai Wang</a>,
<a target="_blank" rel="noopener" href="https://zhengchen1999.github.io/">Zheng Chen</a>, Xing Liu,
Hong Gu, <a target="_blank" rel="noopener" href="http://yulunzhang.com/">Yulun Zhang</a>,
<a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=yDEavdMAAAAJ">Xiaokang
Yang</a>
</p>
<p align="center">
â€œA novel one-step diffusion model for human body restoration,
efficiently handling human motion blur and generic noise in human
images.â€, 2025
</p>
<p align="center">
<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.19742">
<img src="https://img.shields.io/badge/Paper-arXiv-red?logo=arxiv&logoSvg">
</a>
<a target="_blank" rel="noopener" href="https://github.com/gobunu/HAODiff/releases/download/Paper/supp.pdf">
<img src="https://img.shields.io/badge/Supplementary_material-Paper-orange.svg">
</a> <a target="_blank" rel="noopener" href="https://github.com/gobunu/HAODiff/releases">
<img src="https://img.shields.io/github/downloads/gobunu/HAODiff/total.svg">
</a> <a target="_blank" rel="noopener" href="https://github.com/gobunu/HAODiff">
<img src="https://visitor-badge.laobi.icu/badge?page_id=gobunu.HAODiff&right_color=violet">
</a> <a target="_blank" rel="noopener" href="https://github.com/gobunu/HAODiff">
<img src="https://img.shields.io/github/stars/gobunu/HAODiff?style=social">
</a>
</p>
<h4 id="news">ğŸ”¥ğŸ”¥ğŸ”¥ News</h4>
<ul>
<li><h2 id="this-repo-is-released."><strong>2025-05-27:</strong> This
repo is released.</h2></li>
</ul>
<blockquote>
<p><strong>Abstract:</strong> Human-centered images often suffer from
severe generic degradation during transmission and are prone to human
motion blur (HMB), making restoration challenging. Existing research
lacks sufficient focus on these issues, as both problems often coexist
in practice. To address this, we design a degradation pipeline that
simulates the coexistence of HMB and generic noise, generating synthetic
degraded data to train our proposed HAODiff, a human-aware one-step
diffusion. Specifically, we propose a triple-branch dual-prompt guidance
(DPG), which leverages high-quality images, residual noise (LQ minus
HQ), and HMB segmentation masks as training targets. It produces a
positive-negative prompt pair for classifier-free guidance (CFG) in a
single diffusion step. The resulting adaptive dual prompts let HAODiff
exploit CFG more effectively, boosting robustness against diverse
degradations. For fair evaluation, we introduce MPII-Test, a benchmark
rich in combined noise and HMB cases. Extensive experiments show that
our HAODiff surpasses existing state-of-the-art (SOTA) methods in terms
of both quantitative metrics and visual quality on synthetic and
real-world datasets, including our introduced MPII-Test.</p>
</blockquote>
<p align="center">
<img src="HAODiff_pipeline.png" alt="HAODiff_pipeline.png" /> <b>Figure
2:</b> Degradation pipeline overview.
</p>
<p align="center">
<img src="HAODiff_model.png" alt="HAODiff_model.png" /> <b>Figure 3:</b>
Model structure of our HAODiff.
</p>
<table style="width:6%;">
<colgroup>
<col style="width: 5%" />
</colgroup>
<tbody>
<tr>
<td></td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h2 id="todo">âš’ï¸ TODO</h2>
<ul class="task-list">
<li><label><input type="checkbox" />Release code and pretrained
models</label></li>
</ul>
<h2 id="contents">ğŸ”— Contents</h2>
<ul class="task-list">
<li><label><input type="checkbox" />Models</label></li>
<li><label><input type="checkbox" />Testing</label></li>
<li><label><input type="checkbox" />Training</label></li>
<li><label><input type="checkbox" checked="" /><a
href="#Results">Results</a></label></li>
<li><label><input type="checkbox" checked="" /><a
href="#Citation">Citation</a></label></li>
<li><label><input type="checkbox" /><a
href="#Acknowledgements">Acknowledgements</a></label></li>
</ul>
<h2 id="results"><a name="results"></a>ğŸ” Results</h2>
<p>The model <strong>HAODiff</strong> achieved state-of-the-art
performance on both the datasets <strong>PERSONA-Val</strong>,
<strong>PERSONA-Test</strong>, and <strong>MPII-Test</strong>. Detailed
results can be found in the paper.</p>
<details>
<summary>
â€‚Quantitative Comparisons (click to expand)
</summary>
<li>
Results in Table 1 on synthetic PERSONA-Val dataset from the main paper.
<p align="center">
<figure>
<img src="tab_1.png" alt="tab_1.png" />
<figcaption aria-hidden="true">tab_1.png</figcaption>
</figure>
</p>
</li>
<summary>
â€‚Quantitative Comparisons (click to expand)
</summary>
<li>
Results in Table 2 on real-world PERSONA-Test and MPII-Test datasets
from the main paper.
<p align="center">
<figure>
<img src="tab_2.png" alt="tab_2.png" />
<figcaption aria-hidden="true">tab_2.png</figcaption>
</figure>
</p>
</li>
</details>
<details>
<summary>
â€‚Visual Comparisons (click to expand)
</summary>
<li>
Results in Figure 5 on synthetic PERSONA-Val dataset from the main
paper.
<p align="center">
<figure>
<img src="fig5-main.png" alt="fig5-main.png" />
<figcaption aria-hidden="true">fig5-main.png</figcaption>
</figure>
</p>
</li>
<li>
Results in Figure 6 on real-world PERSONA-Test and MPII-Test datasets
from the main paper.
<p align="center">
<figure>
<img src="fig6-main.png" alt="fig6-main.png" />
<figcaption aria-hidden="true">fig6-main.png</figcaption>
</figure>
</p>
</li>
</details>
<details open>
<summary style="margin-left: 2rem;">
â€‚More Comparisons on fabric patterns and texturesâ€¦
</summary>
<li style="margin-left: 2rem;">
Results in Figure 4 from supplemental material.
<p align="center">
<figure>
<img src="fig4-supp.png" alt="fig4-supp.png" />
<figcaption aria-hidden="true">fig4-supp.png</figcaption>
</figure>
</p>
</li>
</details>
<details>
<summary style="margin-left: 2rem;">
â€‚More Comparisons on synthetic PERSONA-Val datasetâ€¦
</summary>
<li style="margin-left: 2rem;">
Results in Figure 5, 6 from supplemental material.
<p align="center">
<figure>
<img src="fig5-supp.png" alt="fig5-supp.png" />
<figcaption aria-hidden="true">fig5-supp.png</figcaption>
</figure>
</p>
<p align="center">
<figure>
<img src="fig6-supp.png" alt="fig6-supp.png" />
<figcaption aria-hidden="true">fig6-supp.png</figcaption>
</figure>
</p>
</li>
</details>
<details>
<summary style="margin-left: 2rem;">
â€‚More Comparisons on real-world PERSONA-Test datasetâ€¦
</summary>
<li style="margin-left: 2rem;">
Results in Figure 7, 8 from supplemental material.
<p align="center">
<figure>
<img src="fig7-supp.png" alt="fig7-supp.png" />
<figcaption aria-hidden="true">fig7-supp.png</figcaption>
</figure>
</p>
<p align="center">
<figure>
<img src="fig8-supp.png" alt="fig8-supp.png" />
<figcaption aria-hidden="true">fig8-supp.png</figcaption>
</figure>
</p>
</li>
</details>
<details>
<summary style="margin-left: 2rem;">
â€‚More Comparisons on real-world MPII-Test datasetâ€¦
</summary>
<li style="margin-left: 2rem;">
Results in Figure 9, 10 from supplemental material.
<p align="center">
<figure>
<img src="fig9-supp.png" alt="fig9-supp.png" />
<figcaption aria-hidden="true">fig9-supp.png</figcaption>
</figure>
</p>
<p align="center">
<figure>
<img src="fig10-supp.png" alt="fig10-supp.png" />
<figcaption aria-hidden="true">fig10-supp.png</figcaption>
</figure>
</p>
</li>
</details>
<details>
<summary style="margin-left: 2rem;">
â€‚More Comparisons on challenge tasksâ€¦
</summary>
<li style="margin-left: 2rem;">
Results in Figure 11, 12 from supplemental material.
<p align="center">
<figure>
<img src="fig11-supp.png" alt="fig11-supp.png" />
<figcaption aria-hidden="true">fig11-supp.png</figcaption>
</figure>
</p>
<p align="center">
<figure>
<img src="fig12-supp.png" alt="fig12-supp.png" />
<figcaption aria-hidden="true">fig12-supp.png</figcaption>
</figure>
</p>
</li>
</details>
<h2 id="citation"><a name="citation"></a>ğŸ“ Citation</h2>
<p>If you find the code helpful in your research or work, please cite
the following paper(s).</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@article&#123;gong2025haodiff,</span><br><span class="line">    title=&#123;&#123;HAODiff: Human-Aware One-Step Diffusion via Dual-Prompt Guidance&#125;&#125;,</span><br><span class="line">    author=&#123;Gong, Jue and Yang, Tingyu and Wang, Jingkai and Chen, Zheng and Liu, Xing and Gu, Hong and Liu, Yutong and Zhang, Yulun and Yang, Xiaokang&#125;,</span><br><span class="line">    journal=&#123;arXiv preprint 2505.19742&#125;,</span><br><span class="line">    year=&#123;2025&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="acknowledgements"><a name="acknowledgements"></a>ğŸ’¡
Acknowledgements</h2>
<p>[TBD]</p>
<!-- ![Visitor Count](https://profile-counter.glitch.me/gobunu/count.svg) -->
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="http://example.com">unswear</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="http://example.com/2025/08/19/HAODiff-NeurIPS-2025/">http://example.com/2025/08/19/HAODiff-NeurIPS-2025/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº <a href="http://example.com" target="_blank">-UNSWEAR-</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%B8%AA%E4%BA%BA%E7%A7%91%E7%A0%94%E9%A1%B9%E7%9B%AE/">ä¸ªäººç§‘ç ”é¡¹ç›®</a></div><div class="post-share"><div class="social-share" data-image="https://imgapi.jinghuashang.cn/random?t=17627393339646338" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/06/30/TSD-SR%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="TSD-SRé˜…è¯»ç¬”è®°"><img class="cover" src="https://imgapi.jinghuashang.cn/random?t=17627393339658625" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">ä¸Šä¸€ç¯‡</div><div class="info-item-2">TSD-SRé˜…è¯»ç¬”è®°</div></div><div class="info-2"><div class="info-item-1">è®ºæ–‡é˜…è¯»ç¬”è®°ï¼šã€ŠTSD-SR: One-Step Diffusion with Target Score Distillation for Real-World Image Super-Resolutionã€‹   å›¾ç‰‡  è®ºæ–‡æ ¸å¿ƒæ€æƒ³ æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º TSD-SR çš„æ–°é¢–æ¡†æ¶ï¼Œæ—¨åœ¨å°†å¼ºå¤§çš„é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹è’¸é¦æˆä¸€ä¸ªé«˜æ•ˆä¸”æœ‰æ•ˆçš„ å•æ­¥ çœŸå®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆReal-ISRï¼‰æ¨¡å‹ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡æ–°é¢–çš„ ç›®æ ‡åˆ†æ•°è’¸é¦ï¼ˆTSDï¼‰...</div></div></div></a><a class="pagination-related" href="/2025/11/10/SODiff-AAAI-2026/" title="SODiff-AAAI-2026"><img class="cover" src="https://imgapi.jinghuashang.cn/random?t=17627393339654922" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">ä¸‹ä¸€ç¯‡</div><div class="info-item-2">SODiff-AAAI-2026</div></div><div class="info-2"><div class="info-item-1"> SODiff: Semantic-Oriented Diffusion Model  for JPEG Compression Artifacts Removal                 Tingyu Yang, Jue Gong, Jinpei Guo, Wenbo Li, Yong Guo, and Yulun Zhang, SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal, arXiv, 2025 ğŸ”¥ğŸ”¥ News  2025-08-10: This repo is released.   Abstract: JPEG, as a widely used image compression standard, often introduces severe visual artifacts when achieving high compression ratios. Although existing deep learning-based...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/10/SODiff-AAAI-2026/" title="SODiff-AAAI-2026"><img class="cover" src="https://imgapi.jinghuashang.cn/random?t=17627393339654922" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-10</div><div class="info-item-2">SODiff-AAAI-2026</div></div><div class="info-2"><div class="info-item-1"> SODiff: Semantic-Oriented Diffusion Model  for JPEG Compression Artifacts Removal                 Tingyu Yang, Jue Gong, Jinpei Guo, Wenbo Li, Yong Guo, and Yulun Zhang, SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal, arXiv, 2025 ğŸ”¥ğŸ”¥ News  2025-08-10: This repo is released.   Abstract: JPEG, as a widely used image compression standard, often introduces severe visual artifacts when achieving high compression ratios. Although existing deep learning-based...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://s21.ax1x.com/2025/06/24/pVeefKS.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">unswear</div><div class="author-info-description">Oh captain, my captain</div><div class="site-data"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/frakenation"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">åšå®¢æŒç»­æ­å»ºä¸­ï½</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">
HAODiff: Human-Aware One-Step Diffusion  via Dual-Prompt Guidance
</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#news"><span class="toc-number">1.0.0.1.</span> <span class="toc-text">ğŸ”¥ğŸ”¥ğŸ”¥ News</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#this-repo-is-released."><span class="toc-number">1.1.</span> <span class="toc-text">2025-05-27: This
repo is released.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#todo"><span class="toc-number">1.2.</span> <span class="toc-text">âš’ï¸ TODO</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#contents"><span class="toc-number">1.3.</span> <span class="toc-text">ğŸ”— Contents</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#results"><span class="toc-number">1.4.</span> <span class="toc-text">ğŸ” Results</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#citation"><span class="toc-number">1.5.</span> <span class="toc-text">ğŸ“ Citation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#acknowledgements"><span class="toc-number">1.6.</span> <span class="toc-text">ğŸ’¡
Acknowledgements</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>æœ€æ–°æ–‡ç« </span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/11/10/SODiff-AAAI-2026/" title="SODiff-AAAI-2026"><img src="https://imgapi.jinghuashang.cn/random?t=17627393339654922" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SODiff-AAAI-2026"/></a><div class="content"><a class="title" href="/2025/11/10/SODiff-AAAI-2026/" title="SODiff-AAAI-2026">SODiff-AAAI-2026</a><time datetime="2025-11-10T01:31:38.000Z" title="å‘è¡¨äº 2025-11-10 09:31:38">2025-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/19/HAODiff-NeurIPS-2025/" title="HAODiff(NeurIPS 2025)"><img src="https://imgapi.jinghuashang.cn/random?t=17627393339646338" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HAODiff(NeurIPS 2025)"/></a><div class="content"><a class="title" href="/2025/08/19/HAODiff-NeurIPS-2025/" title="HAODiff(NeurIPS 2025)">HAODiff(NeurIPS 2025)</a><time datetime="2025-08-19T14:56:42.000Z" title="å‘è¡¨äº 2025-08-19 22:56:42">2025-08-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/30/TSD-SR%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="TSD-SRé˜…è¯»ç¬”è®°"><img src="https://imgapi.jinghuashang.cn/random?t=17627393339658625" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TSD-SRé˜…è¯»ç¬”è®°"/></a><div class="content"><a class="title" href="/2025/06/30/TSD-SR%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="TSD-SRé˜…è¯»ç¬”è®°">TSD-SRé˜…è¯»ç¬”è®°</a><time datetime="2025-06-30T02:15:12.000Z" title="å‘è¡¨äº 2025-06-30 10:15:12">2025-06-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/26/%E5%85%B3%E4%BA%8EDDPM%E7%9A%84%E4%B8%80%E4%BA%9B%E7%96%91%E6%83%91/" title="å…³äºDDPMçš„ä¸€äº›ç–‘æƒ‘"><img src="https://imgapi.jinghuashang.cn/random?t=17627393339665391" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="å…³äºDDPMçš„ä¸€äº›ç–‘æƒ‘"/></a><div class="content"><a class="title" href="/2025/06/26/%E5%85%B3%E4%BA%8EDDPM%E7%9A%84%E4%B8%80%E4%BA%9B%E7%96%91%E6%83%91/" title="å…³äºDDPMçš„ä¸€äº›ç–‘æƒ‘">å…³äºDDPMçš„ä¸€äº›ç–‘æƒ‘</a><time datetime="2025-06-26T02:25:15.000Z" title="å‘è¡¨äº 2025-06-26 10:25:15">2025-06-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/26/StyID/" title="StyIDå­¦ä¹ ä¸æé—®"><img src="https://imgapi.jinghuashang.cn/random?t=17627393339657744" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="StyIDå­¦ä¹ ä¸æé—®"/></a><div class="content"><a class="title" href="/2025/06/26/StyID/" title="StyIDå­¦ä¹ ä¸æé—®">StyIDå­¦ä¹ ä¸æé—®</a><time datetime="2025-06-26T02:14:55.000Z" title="å‘è¡¨äº 2025-06-26 10:14:55">2025-06-26</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://imgapi.jinghuashang.cn/random?t=17627393339646338);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By unswear</div><div class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="æ—¥é—´å’Œå¤œé—´æ¨¡å¼åˆ‡æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>